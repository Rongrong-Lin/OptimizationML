{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510ae3cc",
   "metadata": {},
   "source": [
    "代码1：核支持向量机手写字符识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ace0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "digits=load_digits()\n",
    "X_train,X_test,y_train,y_test=train_test_split(digits.data,digits.target,\n",
    "test_size=0.25,random_state=33)\n",
    "print(\"X train shape:{},X test shape:{}\".format(X_train.shape, X_test.shape))\n",
    "#X train shape:(1347, 64),X test shape:(450, 64),\n",
    "# Normalization\n",
    "ss=StandardScaler()\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.fit_transform(X_test)\n",
    "#Linear SVC\n",
    "lsvc=LinearSVC(C=1, penalty=\"l2\",loss='hinge')\n",
    "lsvc.fit(X_train,y_train)\n",
    "y_predict=lsvc.predict(X_test)\n",
    "print('Accuracy of Linear SVC:',lsvc.score(X_test,y_test))\n",
    "print(classification_report(y_test,y_predict,target_names\n",
    "=digits.target_names.astype(str)))\n",
    "#Polynomial Kernel\n",
    "lsvc1=SVC(C=1,kernel='poly',degree=2)\n",
    "#loss='squared_hinge'\n",
    "lsvc1.fit(X_train,y_train)\n",
    "y_predict=lsvc1.predict(X_test)\n",
    "print('Accuracy of SVC of poly kernel:',lsvc1.score(X_test,y_test))\n",
    "print(classification_report(y_test,y_predict,target_names\n",
    "=digits.target_names.astype(str)))\n",
    "#Gaussian Kernel\n",
    "lsvc2=SVC(C=1,kernel='rbf',gamma=0.01)\n",
    "lsvc2.fit(X_train,y_train)\n",
    "y_predict=lsvc2.predict(X_test)\n",
    "print('Accuracy of SVC of rbf kernel:',lsvc2.score(X_test,y_test))\n",
    "print(classification_report(y_test,y_predict,target_names\n",
    "      =digits.target_names.astype(str)))\n",
    "#Accuracy of Linear SVC: 0.94\n",
    "#Accuracy of SVC of poly kernel: 0.9777777777777777\n",
    "#Accuracy of SVC of rbf kernel: 0.9844444444444445"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d258e6f",
   "metadata": {},
   "source": [
    "代码2： 身高-体重数据的线性回归、岭回归、LASSO回归和核岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2a449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 使用sk-learn的线性回归模型\n",
    "def linear_regression_sk(X, y):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X, y)\n",
    "    print('线性回归解：', 'b：', lin_reg.intercept_, 'w：', lin_reg.coef_)\n",
    "# 岭回归，l2正则化\n",
    "def ridge_regression_analysis(X, y):\n",
    "    from sklearn.linear_model import Ridge\n",
    "    ridge_reg = Ridge(alpha=1, solver='cholesky')\n",
    "    ridge_reg.fit(X, y)\n",
    "    print('岭回归解：', 'b：', ridge_reg.intercept_, 'w：', ridge_reg.coef_)\n",
    "# Lasso 回归，l1正则化\n",
    "def lasso_regression_analysis(X, y):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    lasso_reg = Lasso(alpha=0.1)\n",
    "    lasso_reg.fit(X, y)\n",
    "    print('LASSO回归解：', 'b：', lasso_reg.intercept_, 'w：', lasso_reg.coef_)\n",
    "# 高斯核岭回归\n",
    "def kernel_regression_analysis(X, y):\n",
    "    from sklearn.kernel_ridge import KernelRidge\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    import matplotlib.pyplot as plt\n",
    "    #网格搜索和交叉验证确定最优超参数\n",
    "    kr = GridSearchCV(KernelRidge(kernel='rbf', gamma=20), cv=5,\n",
    "                      param_grid={'alpha': [1e0, 0.1, 1e-2, 1e-3],\n",
    "                                  'gamma': np.logspace(-2, 2, 5)})\n",
    "    kr.fit(X, y)\n",
    "    print('核岭回归误差:',np.linalg.norm(y-kr.predict(X)))\n",
    "    X_plot = np.linspace(150, 190, 100)[:, None]\n",
    "    y_kr = kr.predict(X_plot)\n",
    "    plt.scatter(X, y, c='k', label='data', zorder=1)\n",
    "    plt.plot(X_plot, y_kr, c='g',label='KRR')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #身高体重数据\n",
    "    data=np.array([[152,51],[156,53],[160,54],[164,55],\n",
    "              [168,57],[172,62],[176,62],[180,65],\n",
    "              [184,69],[188,72]])\n",
    "    print(data.shape)\n",
    "    X,y=data[:,0].reshape(-1,1),data[:,1]\n",
    "    linear_regression_sk(X, y)\n",
    "    ridge_regression_analysis(X, y)\n",
    "    lasso_regression_analysis(X, y)\n",
    "    kernel_regression_analysis(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d3431",
   "metadata": {},
   "source": [
    "代码3：鸢尾花数据集的感知机、逻辑回归和Softmax回归分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7865d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "#鸢尾花数据集\n",
    "iris = datasets.load_iris()\n",
    "#print(iris.keys())\n",
    "n_samples, n_features = iris.data.shape\n",
    "print((n_samples, n_features))\n",
    "#print(iris.data[0])\n",
    "print(iris.target_names)\n",
    "print(\"feature_names:\",iris.feature_names)\n",
    "\n",
    "# 感知机分类\n",
    "def perceptron_classify(iris):\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    X = iris[\"data\"][:, 3:]  #花瓣宽度petal width\n",
    "    y = (iris[\"target\"] == 2).astype(np.int)\n",
    "    perceptron_reg = Perceptron()\n",
    "    perceptron_reg.fit(X, y)\n",
    "    print('感知机解：', 'b：', perceptron_reg.intercept_, 'w：', perceptron_reg.coef_)\n",
    "    print('perceptron accuracy:=',perceptron_reg.score(X, y))\n",
    "# logistic回归分类\n",
    "def logistic_classify(iris):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    X = iris[\"data\"][:, 3:]  #花瓣宽度petal width\n",
    "    y = (iris[\"target\"] == 2).astype(np.int)\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X, y)\n",
    "    print('logistic回归解：', 'b：', log_reg.intercept_, 'w：', log_reg.coef_)\n",
    "    print('logistic accuracy:=',log_reg.score(X, y))\n",
    "# softmax回归多分类\n",
    "def softmax_classify(iris):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    X = iris[\"data\"][:, (2, 3)]  #花瓣长度petal length,花瓣宽度petal width\n",
    "    y = iris[\"target\"]\n",
    "    softmax_reg = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\", C=10)\n",
    "    softmax_reg.fit(X, y)\n",
    "    print('softmax回归解：', 'b：', softmax_reg.intercept_, 'w：=\\n', softmax_reg.coef_)\n",
    "    print('softmax accuracy:=',softmax_reg.score(X, y))\n",
    "    predict = softmax_reg.predict([[5, 2]])\n",
    "    predict_pro = softmax_reg.predict_proba([[5, 2]])\n",
    "    print('softmax回归预测为：', predict, '各类概率为', predict_pro)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    perceptron_classify(iris)\n",
    "    logistic_classify(iris)\n",
    "    softmax_classify(iris)\n",
    "    \n",
    "#logistic回归解： b： [-7.1947083] w： [[4.3330846]]\n",
    "#softmax回归解：b： [ 18.87514796   6.3844344  -25.25958236]\n",
    "#w=[[-4.58614563 -2.24129385],[0.16068263 -2.15860167],[4.425463  4.39989552]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e0c03",
   "metadata": {},
   "source": [
    "代码4： 二维卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e478405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=\n",
      "[[4 1 2 4 3]\n",
      " [1 3 3 2 3]\n",
      " [3 4 2 3 1]\n",
      " [1 2 2 2 3]\n",
      " [2 2 4 4 4]]\n",
      "h=\n",
      "[[-1 -1 -1]\n",
      " [-1  8 -1]\n",
      " [-1 -1 -1]]\n",
      "Convolution x*h=\n",
      "[[ -4  -5  -7  -7  -9  -7  -3]\n",
      " [ -5  27  -5   3  19  15  -6]\n",
      " [ -8  -7   4   3  -5  11  -7]\n",
      " [ -5  13  15  -5   6  -5  -7]\n",
      " [ -6  -5  -4  -7  -7  10  -8]\n",
      " [ -3  11   5  20  17  23  -7]\n",
      " [ -2  -4  -8 -10 -12  -8  -4]]\n"
     ]
    }
   ],
   "source": [
    "#2D Convolution\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "x=np.random.randint(1,5,size=(5,5))\n",
    "h=np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])\n",
    "y=scipy.signal.convolve(x,h,mode='full', method='auto')\n",
    "print(\"x=\\n\"+str(x))\n",
    "print(\"h=\\n\"+str(h))\n",
    "print(\"Convolution x*h=\\n\"+str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df722b5",
   "metadata": {},
   "source": [
    "MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbab08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST Dataset\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)  # (60000, 28, 28)\n",
    "print(y_train.shape)  # (60000,)\n",
    "print(X_test.shape)   # (10000, 28, 28)\n",
    "print(y_test.shape)   # (10000,)\n",
    "print(type(X_train))  # <class 'numpy.ndarray'>\n",
    "plt.imshow(X_train[0], cmap=\"Greys\")  # The first image\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816efb30",
   "metadata": {},
   "source": [
    "代码5：3层感知机识别手写字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d79ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.layers import Dropout\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "\n",
    "def mnist_data_split():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    img_rows, img_cols = 28, 28\n",
    "    num_classes = 10\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    x_test = x_test.reshape(10000, 784)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    print(\"x_train shape: \", x_train.shape)\n",
    "    print(\"train samples: \", x_train.shape[0])\n",
    "    print(\"test samples: \", x_test.shape[0])\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    y_train = y_train.astype('int32')\n",
    "    y_test = y_test.astype('int32')\n",
    "    print(\"X train shape:{},X test shape:{},y train shape:{},y test shape:{}\"\n",
    "          .format(x_train.shape, x_test.shape, y_train.shape, y_test.shape))\n",
    "    return  x_train, x_test, y_train, y_test\n",
    "x_train, x_test, y_train, y_test = mnist_data_split()\n",
    "print (\"inputshape is :{}\".format(x_train.shape[1]))\n",
    "\n",
    "def train_mnist_nnet_baseline( x_train, x_test, y_train, y_test):\n",
    "    num_class = 10\n",
    "    epochs = 32\n",
    "    batch_size = 128\n",
    "    input_shape = (784, )\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=input_shape, activation=\"relu\"))\n",
    "    model.add(Dense(32, activation=\"relu\"))\n",
    "    model.add(Dense(num_class, activation=\"softmax\"))\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                  optimizer=\"adam\",metrics=['accuracy'])\n",
    "    history_callback = model.fit(x_train, y_train,verbose=0,batch_size\n",
    "              =batch_size,validation_data=(x_test, y_test),epochs=epochs)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"Test loss: {}\".format(score[0]))\n",
    "    print(\"Test accuracy: {}\".format(score[1]))\n",
    "    print(model.summary())\n",
    "    return history_callback\n",
    "\n",
    "%time callback = train_mnist_nnet_baseline(x_train, x_test, y_train, y_test)\n",
    "#Test loss: 0.13420844078063965\n",
    "#Test accuracy: 0.9732000231742859\n",
    "#Total params: 52,650"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96ee00",
   "metadata": {},
   "source": [
    "代码6：7层卷积神经网络的手写字符识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9536db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D,MaxPooling2D,ZeroPadding2D,GlobalAveragePooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", X_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "print(\"X_test original shape\", X_test.shape)\n",
    "print(\"y_test original shape\", y_test.shape)\n",
    "#Reshape data: 3D-->>4D  (batch, height, width, channels)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train/=255\n",
    "X_test/=255\n",
    "X_train.shape\n",
    "#One-hot编码\n",
    "number_of_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, number_of_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, number_of_classes)\n",
    "#CNN模型架构\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64,(3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization(axis=-1)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "BatchNormalization()\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "BatchNormalization()\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),metrics=['accuracy'])\n",
    "gen = ImageDataGenerator(rotation_range=8,width_shift_range=0.08,\n",
    "       shear_range=0.3,height_shift_range=0.08, zoom_range=0.08)\n",
    "test_gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(X_train,Y_train,batch_size=64)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=64)\n",
    "\n",
    "model.fit_generator(train_generator,steps_per_epoch=60000//64, epochs=2,\n",
    "                    validation_data=test_generator,validation_steps=10000//64)\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test accuracy: \", score[1])\n",
    "#X_train original shape (60000, 28, 28),X_test original shape (10000, 28, 28)\n",
    "#Total params: 594,922, Test accuracy:  0.9932000041007996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9d08ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
